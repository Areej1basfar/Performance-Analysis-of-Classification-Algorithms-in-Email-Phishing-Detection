# -*- coding: utf-8 -*-
"""Performance Analysis of Classification Algorithms in Email Phishing Detection.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Mc_KmAWyWOtZJUWBWWgF6EgM_ezet4MI
"""

import pandas as pd
from sklearn.model_selection import train_test_split

# 1. تحميل البيانات الكاملة
df = pd.read_csv('email_phishing_data.csv')

# 2. فصل الخصائص (X) والهدف (y)
X = df.drop('label', axis=1)
y = df['label']

# 3. تقسيم البيانات: 70% تدريب، 30% اختبار
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# 4. حفظ الملفات الناتجة
X_train.to_csv('X_train.csv', index=False)
X_test.to_csv('X_test.csv', index=False)
y_train.to_csv('y_train.csv', index=False)
y_test.to_csv('y_test.csv', index=False)

print("✅ تم تقسيم البيانات بنجاح وحفظ الملفات:")
print("- X_train.csv")
print("- X_test.csv")
print("- y_train.csv")
print("- y_test.csv")

import pandas as pd
from sklearn.preprocessing import StandardScaler

# 1. تحميل بيانات X
X_train = pd.read_csv('X_train.csv')
X_test = pd.read_csv('X_test.csv')

# 2. تقييس البيانات باستخدام StandardScaler
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# 3. حفظ النتائج في CSV
pd.DataFrame(X_train_scaled, columns=X_train.columns).to_csv('X_train_scaled.csv', index=False)
pd.DataFrame(X_test_scaled, columns=X_test.columns).to_csv('X_test_scaled.csv', index=False)

print("✅ تم تقييس البيانات وحفظ الملفات:")
print("- X_train_scaled.csv")
print("- X_test_scaled.csv")

# ✅ تثبيت مكتبة SMOTE (مرة وحدة فقط)
!pip install -q imbalanced-learn

# ✅ استيراد المكتبات
import pandas as pd
import os
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, classification_report
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from imblearn.over_sampling import SMOTE

# ✅ 1. تحميل البيانات الأصلية
df = pd.read_csv('email_phishing_data.csv')
X = df.drop('label', axis=1)
y = df['label']

# ✅ 2. تقسيم البيانات إلى تدريب واختبار
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# ✅ 3. تطبيق StandardScaler
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# ✅ 4. موازنة بيانات التدريب باستخدام SMOTE
smote = SMOTE(random_state=42)
X_train_balanced, y_train_balanced = smote.fit_resample(X_train_scaled, y_train)

# ✅ 5. تعريف النماذج (بدون ANN أو SVM أو NB)
models = {
    "Random Forest": RandomForestClassifier(random_state=42),
    "KNN": KNeighborsClassifier(),
    "Decision Tree": DecisionTreeClassifier(random_state=42),
    "Logistic Regression": LogisticRegression(max_iter=1000, random_state=42)
}

# ✅ 6. تدريب النماذج وطباعة النتائج وحفظ التوقعات
os.makedirs("Data/Result", exist_ok=True)
accuracies = {}

print("📊 Model Accuracies and Reports:\n")

for name, model in models.items():
    model.fit(X_train_balanced, y_train_balanced)
    preds = model.predict(X_test_scaled)
    acc = round(accuracy_score(y_test, preds) * 100, 2)
    accuracies[name] = acc

    print(f"\n🔹 {name} Accuracy: {acc}%")
    print("📊 Classification Report:")
    print(classification_report(y_test, preds))

    # حفظ النتائج في CSV بدون الخصائص
    result_df = pd.DataFrame({'Actual': y_test.values, 'Predicted': preds})
    result_df.to_csv(f"Data/Result/{name.lower().replace(' ', '_')}_predictions.csv", index=False)

from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score, classification_report

ann_model = MLPClassifier(hidden_layer_sizes=(100,), max_iter=300, random_state=42)
ann_model.fit(X_train_scaled, y_train)
ann_preds = ann_model.predict(X_test_scaled)

print("🔹 ANN Accuracy:", round(accuracy_score(y_test, ann_preds) * 100, 2), "%")
print(classification_report(y_test, ann_preds))

pd.DataFrame({'Actual': y_test.values, 'Predicted': ann_preds}).to_csv("Data/Result/ann_predictions.csv", index=False)

from sklearn.svm import SVC

svm_model = SVC(kernel='rbf', max_iter=5000, random_state=42)
svm_model.fit(X_train_scaled, y_train)
svm_preds = svm_model.predict(X_test_scaled)

print("🔹 SVM Accuracy:", round(accuracy_score(y_test, svm_preds) * 100, 2), "%")
print(classification_report(y_test, svm_preds))

pd.DataFrame({'Actual': y_test.values, 'Predicted': svm_preds}).to_csv("Data/Result/svm_predictions.csv", index=False)

from sklearn.naive_bayes import CategoricalNB
from sklearn.preprocessing import KBinsDiscretizer

binner = KBinsDiscretizer(n_bins=4, encode='ordinal', strategy='quantile')
X_train_binned = binner.fit_transform(X_train)
X_test_binned = binner.transform(X_test)

nb_model = CategoricalNB()
nb_model.fit(X_train_binned, y_train)
nb_preds = nb_model.predict(X_test_binned)

print("🔹 Naive Bayes Accuracy:", round(accuracy_score(y_test, nb_preds) * 100, 2), "%")
print(classification_report(y_test, nb_preds))

pd.DataFrame({'Actual': y_test.values, 'Predicted': nb_preds}).to_csv("Data/Result/naive_bayes_predictions.csv", index=False)

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# ✅ جدول الدقة اليدوي أو تحميله من نتائجك
accuracies = {
    "Random Forest": 98.43,
    "KNN": 94.63,
    "Decision Tree": 98.00,
    "Logistic Regression": 53.90,
    "ANN": 98.71,
    "SVM": 98.70,
    "Naive Bayes": 86.00  # غيّريها إذا عندك الرقم الفعلي
}

# تحويله إلى DataFrame
df_acc = pd.DataFrame(list(accuracies.items()), columns=["Model", "Accuracy"])

# ✅ رسم متطور باستخدام seaborn
plt.figure(figsize=(10, 6))
sns.set(style="whitegrid")
palette = sns.color_palette("Set2")

barplot = sns.barplot(x="Accuracy", y="Model", data=df_acc, palette=palette)
barplot.bar_label(barplot.containers[0], fmt='%.2f%%', label_type='edge', padding=3)

plt.title("🔍 Accuracy Comparison of ML Models", fontsize=14)
plt.xlabel("Accuracy (%)", fontsize=12)
plt.ylabel("Model", fontsize=12)
plt.xlim(0, 100)
plt.tight_layout()
plt.show()