# -*- coding: utf-8 -*-
"""Performance Analysis of Classification Algorithms in Email Phishing Detection.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Mc_KmAWyWOtZJUWBWWgF6EgM_ezet4MI
"""

import pandas as pd
from sklearn.model_selection import train_test_split

# 1. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙƒØ§Ù…Ù„Ø©
df = pd.read_csv('email_phishing_data.csv')

# 2. ÙØµÙ„ Ø§Ù„Ø®ØµØ§Ø¦Øµ (X) ÙˆØ§Ù„Ù‡Ø¯Ù (y)
X = df.drop('label', axis=1)
y = df['label']

# 3. ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: 70% ØªØ¯Ø±ÙŠØ¨ØŒ 30% Ø§Ø®ØªØ¨Ø§Ø±
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# 4. Ø­ÙØ¸ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù†Ø§ØªØ¬Ø©
X_train.to_csv('X_train.csv', index=False)
X_test.to_csv('X_test.csv', index=False)
y_train.to_csv('y_train.csv', index=False)
y_test.to_csv('y_test.csv', index=False)

print("âœ… ØªÙ… ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ù†Ø¬Ø§Ø­ ÙˆØ­ÙØ¸ Ø§Ù„Ù…Ù„ÙØ§Øª:")
print("- X_train.csv")
print("- X_test.csv")
print("- y_train.csv")
print("- y_test.csv")

import pandas as pd
from sklearn.preprocessing import StandardScaler

# 1. ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª X
X_train = pd.read_csv('X_train.csv')
X_test = pd.read_csv('X_test.csv')

# 2. ØªÙ‚ÙŠÙŠØ³ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… StandardScaler
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# 3. Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ CSV
pd.DataFrame(X_train_scaled, columns=X_train.columns).to_csv('X_train_scaled.csv', index=False)
pd.DataFrame(X_test_scaled, columns=X_test.columns).to_csv('X_test_scaled.csv', index=False)

print("âœ… ØªÙ… ØªÙ‚ÙŠÙŠØ³ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ­ÙØ¸ Ø§Ù„Ù…Ù„ÙØ§Øª:")
print("- X_train_scaled.csv")
print("- X_test_scaled.csv")

# âœ… ØªØ«Ø¨ÙŠØª Ù…ÙƒØªØ¨Ø© SMOTE (Ù…Ø±Ø© ÙˆØ­Ø¯Ø© ÙÙ‚Ø·)
!pip install -q imbalanced-learn

# âœ… Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª
import pandas as pd
import os
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, classification_report
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from imblearn.over_sampling import SMOTE

# âœ… 1. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£ØµÙ„ÙŠØ©
df = pd.read_csv('email_phishing_data.csv')
X = df.drop('label', axis=1)
y = df['label']

# âœ… 2. ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ ØªØ¯Ø±ÙŠØ¨ ÙˆØ§Ø®ØªØ¨Ø§Ø±
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# âœ… 3. ØªØ·Ø¨ÙŠÙ‚ StandardScaler
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# âœ… 4. Ù…ÙˆØ§Ø²Ù†Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… SMOTE
smote = SMOTE(random_state=42)
X_train_balanced, y_train_balanced = smote.fit_resample(X_train_scaled, y_train)

# âœ… 5. ØªØ¹Ø±ÙŠÙ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ (Ø¨Ø¯ÙˆÙ† ANN Ø£Ùˆ SVM Ø£Ùˆ NB)
models = {
    "Random Forest": RandomForestClassifier(random_state=42),
    "KNN": KNeighborsClassifier(),
    "Decision Tree": DecisionTreeClassifier(random_state=42),
    "Logistic Regression": LogisticRegression(max_iter=1000, random_state=42)
}

# âœ… 6. ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ ÙˆØ·Ø¨Ø§Ø¹Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙˆØ­ÙØ¸ Ø§Ù„ØªÙˆÙ‚Ø¹Ø§Øª
os.makedirs("Data/Result", exist_ok=True)
accuracies = {}

print("ğŸ“Š Model Accuracies and Reports:\n")

for name, model in models.items():
    model.fit(X_train_balanced, y_train_balanced)
    preds = model.predict(X_test_scaled)
    acc = round(accuracy_score(y_test, preds) * 100, 2)
    accuracies[name] = acc

    print(f"\nğŸ”¹ {name} Accuracy: {acc}%")
    print("ğŸ“Š Classification Report:")
    print(classification_report(y_test, preds))

    # Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ CSV Ø¨Ø¯ÙˆÙ† Ø§Ù„Ø®ØµØ§Ø¦Øµ
    result_df = pd.DataFrame({'Actual': y_test.values, 'Predicted': preds})
    result_df.to_csv(f"Data/Result/{name.lower().replace(' ', '_')}_predictions.csv", index=False)

from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score, classification_report

ann_model = MLPClassifier(hidden_layer_sizes=(100,), max_iter=300, random_state=42)
ann_model.fit(X_train_scaled, y_train)
ann_preds = ann_model.predict(X_test_scaled)

print("ğŸ”¹ ANN Accuracy:", round(accuracy_score(y_test, ann_preds) * 100, 2), "%")
print(classification_report(y_test, ann_preds))

pd.DataFrame({'Actual': y_test.values, 'Predicted': ann_preds}).to_csv("Data/Result/ann_predictions.csv", index=False)

from sklearn.svm import SVC

svm_model = SVC(kernel='rbf', max_iter=5000, random_state=42)
svm_model.fit(X_train_scaled, y_train)
svm_preds = svm_model.predict(X_test_scaled)

print("ğŸ”¹ SVM Accuracy:", round(accuracy_score(y_test, svm_preds) * 100, 2), "%")
print(classification_report(y_test, svm_preds))

pd.DataFrame({'Actual': y_test.values, 'Predicted': svm_preds}).to_csv("Data/Result/svm_predictions.csv", index=False)

from sklearn.naive_bayes import CategoricalNB
from sklearn.preprocessing import KBinsDiscretizer

binner = KBinsDiscretizer(n_bins=4, encode='ordinal', strategy='quantile')
X_train_binned = binner.fit_transform(X_train)
X_test_binned = binner.transform(X_test)

nb_model = CategoricalNB()
nb_model.fit(X_train_binned, y_train)
nb_preds = nb_model.predict(X_test_binned)

print("ğŸ”¹ Naive Bayes Accuracy:", round(accuracy_score(y_test, nb_preds) * 100, 2), "%")
print(classification_report(y_test, nb_preds))

pd.DataFrame({'Actual': y_test.values, 'Predicted': nb_preds}).to_csv("Data/Result/naive_bayes_predictions.csv", index=False)

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# âœ… Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø¯Ù‚Ø© Ø§Ù„ÙŠØ¯ÙˆÙŠ Ø£Ùˆ ØªØ­Ù…ÙŠÙ„Ù‡ Ù…Ù† Ù†ØªØ§Ø¦Ø¬Ùƒ
accuracies = {
    "Random Forest": 98.43,
    "KNN": 94.63,
    "Decision Tree": 98.00,
    "Logistic Regression": 53.90,
    "ANN": 98.71,
    "SVM": 98.70,
    "Naive Bayes": 86.00  # ØºÙŠÙ‘Ø±ÙŠÙ‡Ø§ Ø¥Ø°Ø§ Ø¹Ù†Ø¯Ùƒ Ø§Ù„Ø±Ù‚Ù… Ø§Ù„ÙØ¹Ù„ÙŠ
}

# ØªØ­ÙˆÙŠÙ„Ù‡ Ø¥Ù„Ù‰ DataFrame
df_acc = pd.DataFrame(list(accuracies.items()), columns=["Model", "Accuracy"])

# âœ… Ø±Ø³Ù… Ù…ØªØ·ÙˆØ± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… seaborn
plt.figure(figsize=(10, 6))
sns.set(style="whitegrid")
palette = sns.color_palette("Set2")

barplot = sns.barplot(x="Accuracy", y="Model", data=df_acc, palette=palette)
barplot.bar_label(barplot.containers[0], fmt='%.2f%%', label_type='edge', padding=3)

plt.title("ğŸ” Accuracy Comparison of ML Models", fontsize=14)
plt.xlabel("Accuracy (%)", fontsize=12)
plt.ylabel("Model", fontsize=12)
plt.xlim(0, 100)
plt.tight_layout()
plt.show()